{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s1_cookies_vs_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "import os\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Define the function for test statistic (difference of means)\n",
    "def test_statistic(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "path = os.getcwd() + \"/datasets-stats/s1_cookies_vs_profile.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Get unique alias\n",
    "aliases = df['alias'].unique()\n",
    "\n",
    "# Generate all pairs of aliases\n",
    "pairs = list(itertools.combinations(aliases, 2))\n",
    "\n",
    "# Perform permutation test for each pair\n",
    "for pair in pairs:\n",
    "    group1 = df[df['alias'] == pair[0]]['ct'].to_numpy()\n",
    "    group2 = df[df['alias'] == pair[1]]['ct'].to_numpy()\n",
    "    \n",
    "    result = stats.permutation_test((group1, group2), \n",
    "                                    test_statistic,\n",
    "                                    vectorized=False,\n",
    "                                    alternative='two-sided',\n",
    "                                    permutation_type='independent')\n",
    "    \n",
    "    # Calculate bootstrap confidence intervals for the mean\n",
    "    ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "    ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "    \n",
    "    print(f'Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s2_1s-3rd_vs_profile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1st-party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "import os\n",
    "\n",
    "path = os.getcwd() + \"/datasets-stats/s2_1s-3rd_vs_profile.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df.dropna(subset=['is_third_party'])\n",
    "\n",
    "# Create a new column combining 'alias' and 'is_third_party'\n",
    "df['alias_third_party'] = df['alias'].astype(str) + '_' + df['is_third_party'].astype(str)\n",
    "\n",
    "# Get unique alias_third_party\n",
    "aliases_third_party = df['alias_third_party'].unique()\n",
    "\n",
    "# Generate all pairs of alias_third_party\n",
    "pairs = list(itertools.combinations(aliases_third_party, 2))\n",
    "\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Perform permutation test for each pair\n",
    "for pair in pairs:\n",
    "    group1 = df[df['alias_third_party'] == pair[0]]['ct'].to_numpy()\n",
    "    group2 = df[df['alias_third_party'] == pair[1]]['ct'].to_numpy()\n",
    "    \n",
    "    result = stats.permutation_test((group1, group2), \n",
    "                                    #func=test_statistic, \n",
    "                                    #method='exact',\n",
    "                                    test_statistic,\n",
    "                                    vectorized=False,\n",
    "                                    alternative='two-sided',\n",
    "                                    permutation_type='independent')\n",
    "    \n",
    "    # Calculate bootstrap confidence intervals for the mean\n",
    "    ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "    ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "    \n",
    "    \n",
    "    print(f'Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s3_cat_cookies_vs_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "\n",
    "# Load the dataset\n",
    "path = os.getcwd() + \"/datasets-stats/s3_cat_cookies_vs_profile.csv\"\n",
    "\n",
    "df = pd.read_csv(path) \n",
    "\n",
    "# Get unique categories\n",
    "categories = df['category'].unique()\n",
    "\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Prepare function for permutation test\n",
    "def test_statistic(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "# Iterate over each category\n",
    "for category in categories:\n",
    "    # Get unique aliases within this category\n",
    "    aliases_in_category = df[df['category'] == category]['alias'].unique()\n",
    "\n",
    "    # Generate all pairs of aliases\n",
    "    pairs = list(itertools.combinations(aliases_in_category, 2))\n",
    "\n",
    "    # Perform permutation test for each pair\n",
    "    for pair in pairs:\n",
    "        group1 = df[(df['alias'] == pair[0]) & (df['category'] == category)]['ct'].to_numpy()\n",
    "        group2 = df[(df['alias'] == pair[1]) & (df['category'] == category)]['ct'].to_numpy()\n",
    "\n",
    "        result = permutation_test((group1, group2), \n",
    "                                  test_statistic,\n",
    "                                  vectorized=False,\n",
    "                                  alternative='two-sided',\n",
    "                                  permutation_type='independent')\n",
    "\n",
    "        # Calculate bootstrap confidence intervals for the mean\n",
    "        ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "        ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "        \n",
    "\n",
    "        print(f'Category: {category}, Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import os\n",
    "from scipy.stats import permutation_test\n",
    "\n",
    "# Load the dataset\n",
    "path = os.getcwd() + \"/datasets-stats/s3_cat_cookies_vs_profile.csv\"\n",
    "df = pd.read_csv(path) \n",
    "\n",
    "# Get unique categories\n",
    "categories = df['category'].unique()\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "def test_statistic(a, b):\n",
    "    \"\"\"Statistic for permutation test.\"\"\"\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "def cohen_d(x, y):\n",
    "    \"\"\"Calculate Cohen's d for effect size.\"\"\"\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
    "\n",
    "# Iterate over each category\n",
    "for category in categories:\n",
    "    # Get unique aliases within this category\n",
    "    aliases_in_category = df[df['category'] == category]['alias'].unique()\n",
    "\n",
    "    # Generate all pairs of aliases\n",
    "    pairs = list(itertools.combinations(aliases_in_category, 2))\n",
    "\n",
    "    # Perform permutation test for each pair\n",
    "    for pair in pairs:\n",
    "        group1 = df[(df['alias'] == pair[0]) & (df['category'] == category)]['ct'].to_numpy()\n",
    "        group2 = df[(df['alias'] == pair[1]) & (df['category'] == category)]['ct'].to_numpy()\n",
    "\n",
    "        result = permutation_test((group1, group2), \n",
    "                                  test_statistic,\n",
    "                                  vectorized=False,\n",
    "                                  alternative='two-sided',\n",
    "                                  permutation_type='independent')\n",
    "\n",
    "        # Calculate bootstrap confidence intervals for the mean\n",
    "        ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "        ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "        \n",
    "        # Calculate Cohen's d for effect size\n",
    "        d = cohen_d(group1, group2)\n",
    "\n",
    "        print(f'Category: {category}, Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}, Cohen\\'s d: {d}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s4_localstorage_vs_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "import os\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "path = os.getcwd() + \"/datasets-stats/s4_localstorage_vs_profile.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Define the function for test statistic (difference of means)\n",
    "def test_statistic(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "\n",
    "# Get unique alias\n",
    "aliases = df['alias'].unique()\n",
    "\n",
    "# Generate all pairs of aliases\n",
    "pairs = list(itertools.combinations(aliases, 2))\n",
    "\n",
    "# Perform permutation test for each pair\n",
    "for pair in pairs:\n",
    "    group1 = df[df['alias'] == pair[0]]['ct'].to_numpy()\n",
    "    group2 = df[df['alias'] == pair[1]]['ct'].to_numpy()\n",
    "    \n",
    "    result = stats.permutation_test((group1, group2), \n",
    "                                    test_statistic,\n",
    "                                    vectorized=False,\n",
    "                                    alternative='two-sided',\n",
    "                                    permutation_type='independent')\n",
    "    \n",
    "    # Calculate bootstrap confidence intervals for the mean\n",
    "    ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "    ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "    \n",
    "    print(f'Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s5_tracking_vs_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "import os\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "path = os.getcwd() + \"/datasets-stats/s5_tracking_vs_profile.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Define the function for test statistic (difference of means)\n",
    "def test_statistic(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "\n",
    "# Get unique alias\n",
    "aliases = df['alias'].unique()\n",
    "\n",
    "# Generate all pairs of aliases\n",
    "pairs = list(itertools.combinations(aliases, 2))\n",
    "\n",
    "# Perform permutation test for each pair\n",
    "for pair in pairs:\n",
    "    group1 = df[df['alias'] == pair[0]]['ct'].to_numpy()\n",
    "    group2 = df[df['alias'] == pair[1]]['ct'].to_numpy()\n",
    "    \n",
    "    result = stats.permutation_test((group1, group2), \n",
    "                                    test_statistic,\n",
    "                                    vectorized=False,\n",
    "                                    alternative='two-sided',\n",
    "                                    permutation_type='independent')\n",
    "    \n",
    "    # Calculate bootstrap confidence intervals for the mean\n",
    "    ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "    ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "    \n",
    "    print(f'Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s6_first_third_rejectall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "path = os.getcwd() + \"/datasets-stats/s2_1s-3rd_vs_profile.csv\"\n",
    "\n",
    "df=pd.read_csv(path)\n",
    "df = df.dropna(subset=['is_third_party'])\n",
    "\n",
    "df = df[df['alias'].isin([2, 4])]\n",
    "\n",
    "# Create a new column combining 'alias' and 'is_third_party'\n",
    "df['alias_third_party'] = df['alias'].astype(str) + '_' + df['is_third_party'].astype(str)\n",
    "\n",
    "# Get unique alias_third_party\n",
    "aliases_third_party = df['alias_third_party'].unique()\n",
    "\n",
    "# Generate all pairs of alias_third_party\n",
    "pairs = list(itertools.combinations(aliases_third_party, 2))\n",
    "\n",
    "# Define the function for test statistic (difference of means)\n",
    "def test_statistic(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Perform permutation test for each pair\n",
    "for pair in pairs:\n",
    "    group1 = df[df['alias_third_party'] == pair[0]]['ct'].to_numpy()\n",
    "    group2 = df[df['alias_third_party'] == pair[1]]['ct'].to_numpy()\n",
    "\n",
    "    result = stats.permutation_test((group1, group2), test_statistic, \n",
    "                                    vectorized=False, alternative='two-sided',\n",
    "                                    permutation_type='independent')\n",
    "    \n",
    "\n",
    "    # Calculate bootstrap confidence intervals for the mean\n",
    "    ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "    ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "    print(f'Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n",
    " \n",
    "\n",
    "print(\"Only check 2_1.0, 4_1.0 and 2_0.0, 4_0.0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s7_localstorage_vs_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "import os\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Define the function for test statistic (difference of means)\n",
    "def test_statistic(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "path = os.getcwd() + \"/datasets-stats/s1_cookies_vs_profile.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df[df['alias'].isin([\"#3\", \"#7\",\"#8\"])]\n",
    "\n",
    "\n",
    "# Get unique alias\n",
    "aliases = df['alias'].unique()\n",
    "\n",
    "# Generate all pairs of aliases\n",
    "pairs = list(itertools.combinations(aliases, 2))\n",
    "\n",
    "# Perform permutation test for each pair\n",
    "for pair in pairs:\n",
    "    group1 = df[df['alias'] == pair[0]]['ct'].to_numpy()\n",
    "    group2 = df[df['alias'] == pair[1]]['ct'].to_numpy()\n",
    "    \n",
    "    result = stats.permutation_test((group1, group2), \n",
    "                                    test_statistic,\n",
    "                                    vectorized=False,\n",
    "                                    alternative='two-sided',\n",
    "                                    permutation_type='independent')\n",
    "    \n",
    "    # Calculate bootstrap confidence intervals for the mean\n",
    "    ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "    ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "    \n",
    "    print(f'Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## s8_cat_ls_vs_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "import os\n",
    "\n",
    "path = os.getcwd() + \"/datasets-stats/s8_cat_ls_vs_profile.csv\"\n",
    "\n",
    "df_main = pd.read_csv(path)\n",
    "\n",
    "#Unknown\n",
    "df = df_main[df_main['category']=='Unknown']  \n",
    "uniq = pd.unique(df['alias'])\n",
    "params=[]\n",
    "for item in uniq:\n",
    "    params.append(df[df['alias']==item]['ct'])\n",
    "cat_unknown=f_oneway(*params)\n",
    "\n",
    "#Targeting/Advertising\n",
    "df = df_main[df_main['category']=='Targeting/Advertising']\n",
    "uniq = pd.unique(df['alias'])\n",
    "params=[]\n",
    "for item in uniq:\n",
    "    params.append(df[df['alias']==item]['ct'])\n",
    "cat_targeting=f_oneway(*params)\n",
    "\n",
    "#Performance\n",
    "df = df_main[df_main['category']=='Performance']\n",
    "uniq = pd.unique(df['alias'])\n",
    "params=[]\n",
    "for item in uniq:\n",
    "    params.append(df[df['alias']==item]['ct'])\n",
    "cat_perf=f_oneway(*params)\n",
    "\n",
    "#Strictly Necessary\n",
    "df = df_main[df_main['category']=='Strictly Necessary']\n",
    "uniq = pd.unique(df['alias'])\n",
    "params=[]\n",
    "for item in uniq:\n",
    "    params.append(df[df['alias']==item]['ct'])\n",
    "cat_strict=f_oneway(*params)\n",
    "    \n",
    "\n",
    "#Functionality\n",
    "df = df_main[df_main['category']=='Functionality']\n",
    "uniq = pd.unique(df['alias'])\n",
    "params=[]\n",
    "for item in uniq:\n",
    "    params.append(df[df['alias']==item]['ct'])\n",
    "cat_func=f_oneway(*params)\n",
    " \n",
    "\n",
    "\n",
    "results={}\n",
    "results['Unknown']=cat_unknown\n",
    "results['Targeting/Advertising']=cat_targeting\n",
    "results['Performance']=cat_perf\n",
    "results['Strictly Necessary']=cat_strict\n",
    "results['Functionality']=cat_func\n",
    "\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s9_tracking_vs_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from scipy.stats import permutation_test\n",
    "import os\n",
    "\n",
    "def bootstrap_ci(data, statistic, alpha):\n",
    "    \"\"\"Compute bootstrap confidence interval for given data and statistic.\"\"\"\n",
    "    bs_replicates = np.empty(10000)\n",
    "    \n",
    "    for i in range(10000):\n",
    "        bs_sample = np.random.choice(data, len(data))\n",
    "        bs_replicates[i] = statistic(bs_sample)\n",
    "        \n",
    "    return np.percentile(bs_replicates, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "\n",
    "# Define the function for test statistic (difference of means)\n",
    "def test_statistic(a, b):\n",
    "    return np.mean(a) - np.mean(b)\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "path = os.getcwd() + \"/datasets-stats/s9_tracking_vs_profile.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Get unique alias\n",
    "aliases = df['alias'].unique()\n",
    "\n",
    "# Generate all pairs of aliases\n",
    "pairs = list(itertools.combinations(aliases, 2))\n",
    "\n",
    "# Perform permutation test for each pair\n",
    "for pair in pairs:\n",
    "    group1 = df[df['alias'] == pair[0]]['ct'].to_numpy()\n",
    "    group2 = df[df['alias'] == pair[1]]['ct'].to_numpy()\n",
    "    \n",
    "    result = stats.permutation_test((group1, group2), \n",
    "                                    test_statistic,\n",
    "                                    vectorized=False,\n",
    "                                    alternative='two-sided',\n",
    "                                    permutation_type='independent')\n",
    "    \n",
    "    # Calculate bootstrap confidence intervals for the mean\n",
    "    ci_group1 = bootstrap_ci(group1, np.mean, 0.05)\n",
    "    ci_group2 = bootstrap_ci(group2, np.mean, 0.05)\n",
    "    \n",
    "    print(f'Pair: {pair}, P-value: {result.pvalue}, CI Group1: {ci_group1}, CI Group2: {ci_group2}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## s10 multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skbio.stats.distance import permanova\n",
    "from skbio import DistanceMatrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import os \n",
    "\n",
    "# Load the data\n",
    "path = os.getcwd() + \"/datasets-stats/s10_multiple_runs_scope.zip\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "# Create a pivot table with sum of ct for each combination of measurement_id, browser_id, and category\n",
    "pivot_table = pd.pivot_table(df, values='ct', index=['measurement_id', 'browser_id'], columns=['category'], aggfunc='sum', fill_value=0)\n",
    "\n",
    "# Calculate Euclidean distance matrix\n",
    "distance_matrix = euclidean_distances(pivot_table.values)\n",
    "distance_matrix = DistanceMatrix(distance_matrix)\n",
    "\n",
    "# Prepare the grouping variable (measurement_id)\n",
    "grouping = pivot_table.index.get_level_values('measurement_id')\n",
    "\n",
    "# Perform PERMANOVA\n",
    "result = permanova(distance_matrix, grouping, permutations=9999)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s11: o matic all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(os.getcwd() + '/datasets-plots/p11_stats_omatic_all_settings.zip')\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Perform Kruskal-Wallis test for each category, and if significant, perform Dunn's test\n",
    "for category in df['category'].unique():\n",
    "    data = {browser: df.loc[(df['category'] == category) & (df['browser_id'] == browser), 'ct'].values for browser in df['browser_id'].unique()}\n",
    "    h_statistic, p_value = stats.kruskal(*data.values())\n",
    "    if p_value < 0.05:\n",
    "        posthoc = sp.posthoc_dunn(df[df['category'] == category], val_col='ct', group_col='browser_id', p_adjust = 'holm')\n",
    "        results[category] = posthoc\n",
    "\n",
    "# Print results and mark the significant differences with \"✓\" and non-significant with \"✖\"\n",
    "for category, result in results.items():\n",
    "    print(\"Category:\", category)\n",
    "    result = result.applymap(lambda x: round(x,2) if x < 0.05 else round(x,2))\n",
    "    print(result)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we calculate kruskal +  η2\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "import os\n",
    "\n",
    "path = os.getcwd() + \"/datasets-stats/s10_multiple_runs_scope.zip\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Replace spaces with underscore in the 'category' column\n",
    "df['category'] = df['category'].str.replace(' ', '_')\n",
    "\n",
    "# Create a new column 'browser_category'\n",
    "df['browser_category'] = df['category'] + \"_\" + df['browser_id']\n",
    "\n",
    "# Get the unique browser_categories\n",
    "browser_categories = df['browser_category'].unique()\n",
    "\n",
    "# Get the unique measurement_ids\n",
    "measurement_ids = df['measurement_id'].unique()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Perform Kruskal-Wallis test for each browser_category across different measurement_id\n",
    "for browser_category in browser_categories:\n",
    "    data = [df[(df['browser_category'] == browser_category) & (df['measurement_id'] == measurement_id)]['ct']\n",
    "            for measurement_id in measurement_ids]\n",
    "    H, pval = kruskal(*data)\n",
    "    # calculate eta squared\n",
    "    n = sum([len(d) for d in data])\n",
    "    eta_squared = H / (n - 1)\n",
    "    results.append((browser_category, H, round(pval,2), eta_squared))\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['browser_category', 'H-statistic', 'p-value', 'eta-squared'])\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect size (eta-squared)  results_df\n",
    "import numpy as np\n",
    "\n",
    "print(\"mean: \" + str(np.mean(results_df[\"eta-squared\"])))\n",
    "print(\"std: \" + str(np.std(results_df[\"eta-squared\"])))\n",
    "print(\"min: \" + str(np.min(results_df[\"eta-squared\"])))\n",
    "print(\"max: \" + str(np.max(results_df[\"eta-squared\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "c626abb653ac561c1ecdb9e2f29b2bd3dc8558f48133bd445bb497908c6d6124"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
